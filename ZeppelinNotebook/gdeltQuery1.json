{"paragraphs":[{"text":"import org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.sql.{DataFrame, SparkSession}\nimport org.apache.spark.input.PortableDataStream\nimport org.apache.spark.sql.functions._\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\nimport com.datastax.spark.connector.cql.CassandraConnector\nimport org.apache.spark.sql.cassandra._\n\nimport org.apache.spark.rdd.RDD\n\nimport spark.implicits._\nval AWS_ID = \"ASIATATIKUDEPGIKRX7U\"\nval AWS_KEY = \"eFcCfe102hBpKuqNYu+ftfXBKw3CRDc778XUfQKS\"\nval AWS_TOKEN = \"FwoGZXIvYXdzEHEaDCvYeYPJmwLsNeE6GyLMAVMNSbiFqj4XVtMlP8ZJgy3bEJLwwtp5e1HN4VefHrVBaltIMp8mr0LaQC5N4AVEFl+X3do1EI/fYWpSZOCGjvzgCsi9QX0uwf/E3eA6Tqd3w+tZGyKSa1Lx3wvFjWiWwZeNJvREUn+r3xamVTozpvIfym83Wd39JxBsMHHrEhOVM9+kPu474Ctb6DmUWcWknyrCnFtvhX1hLdt5/3Bg/eXdXR4JIej47kpm6xW3SKO/JGcvxEu8OYk9y0fsnsUUXfJvTZIyqt6PQMW3KCjprJXxBTIti2/D7iBAbpEKRy0fAEYoIWbzMtCMCui1lbV+IrLS30xLjGYgsfr+xgJ2/ENL\"\nval s3_name = \"gael-sav-telecom-gdelt2019-new\"\n\nsc.hadoopConfiguration.set(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\nsc.hadoopConfiguration.set(\"fs.s3a.access.key\", AWS_ID)\nsc.hadoopConfiguration.set(\"fs.s3a.secret.key\", AWS_KEY)\nsc.hadoopConfiguration.set(\"fs.s3a.session.token\", AWS_TOKEN)\n\n\n\n// *** DOWNLOAD DATA ***\n\n// *** Events ***\nval textRDDEvents: RDD[String] = sc.binaryFiles(\"s3://\" + s3_name + \"/20181201*.export.CSV.zip\").\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\n// *** Mentions ***\nval textRDDMentions: RDD[String] = sc.binaryFiles(\"s3://\" + s3_name + \"/2018120105*.mentions.CSV.zip\").\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\n// *** Relation graph ***\nval textRDDRelations: RDD[String] = sc.binaryFiles(\"s3://\" + s3_name + \"/2018120105*.gkg.csv.zip\").\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\n\n// EVENTS\n\nval dfEventsRenamed: DataFrame = textRDDEvents.toDF.withColumn(\"GLOBALEVENTID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"Day\", split($\"value\", \"\\\\t\").getItem(1))\n.withColumn(\"MonthYear\", split($\"value\", \"\\\\t\").getItem(2))\n.withColumn(\"Year\", split($\"value\", \"\\\\t\").getItem(3))\n.withColumn(\"FractionDate\", split($\"value\", \"\\\\t\").getItem(4))\n.withColumn(\"Actor1Code\", split($\"value\", \"\\\\t\").getItem(5))\n.withColumn(\"Actor1Name\", split($\"value\", \"\\\\t\").getItem(6))\n.withColumn(\"Actor1CountryCode\", split($\"value\", \"\\\\t\").getItem(7))\n.withColumn(\"Actor1KnownGroupCode\", split($\"value\", \"\\\\t\").getItem(8))\n.withColumn(\"Actor1EthnicCode\", split($\"value\", \"\\\\t\").getItem(9))\n.withColumn(\"Actor1Religion1Code\", split($\"value\", \"\\\\t\").getItem(10))\n.withColumn(\"Actor1Religion2Code\", split($\"value\", \"\\\\t\").getItem(11))\n.withColumn(\"Actor1Type1Code\", split($\"value\", \"\\\\t\").getItem(12))\n.withColumn(\"Actor1Type2Code\", split($\"value\", \"\\\\t\").getItem(13))\n.withColumn(\"Actor1Type3Code\", split($\"value\", \"\\\\t\").getItem(14))\n.withColumn(\"Actor2Code\", split($\"value\", \"\\\\t\").getItem(15))\n.withColumn(\"Actor2Name\", split($\"value\", \"\\\\t\").getItem(16))\n.withColumn(\"Actor2CountryCode\", split($\"value\", \"\\\\t\").getItem(17))\n.withColumn(\"Actor2KnownGroupCode\", split($\"value\", \"\\\\t\").getItem(18))\n.withColumn(\"Actor2EthnicCode\", split($\"value\", \"\\\\t\").getItem(19))\n.withColumn(\"Actor2Religion1Code\", split($\"value\", \"\\\\t\").getItem(20))\n.withColumn(\"Actor2Religion2Code\", split($\"value\", \"\\\\t\").getItem(21))\n.withColumn(\"Actor2Type1Code\", split($\"value\", \"\\\\t\").getItem(22))\n.withColumn(\"Actor2Type2Code\", split($\"value\", \"\\\\t\").getItem(23))\n.withColumn(\"Actor2Type3Code\", split($\"value\", \"\\\\t\").getItem(24))\n.withColumn(\"IsRootEvent\", split($\"value\", \"\\\\t\").getItem(25))\n.withColumn(\"EventCode\", split($\"value\", \"\\\\t\").getItem(26))\n.withColumn(\"EventBaseCode\", split($\"value\", \"\\\\t\").getItem(27))\n.withColumn(\"EventRootCode\", split($\"value\", \"\\\\t\").getItem(28))\n.withColumn(\"QuadClass\", split($\"value\", \"\\\\t\").getItem(29))\n.withColumn(\"GoldsteinScale\", split($\"value\", \"\\\\t\").getItem(30))\n.withColumn(\"NumMentions\", split($\"value\", \"\\\\t\").getItem(31))\n.withColumn(\"NumSources\", split($\"value\", \"\\\\t\").getItem(32))\n.withColumn(\"NumArticles\", split($\"value\", \"\\\\t\").getItem(33))\n.withColumn(\"AvgTone\", split($\"value\", \"\\\\t\").getItem(34))\n.withColumn(\"Actor1Geo_Type\", split($\"value\", \"\\\\t\").getItem(35))\n.withColumn(\"Actor1Geo_FullName\", split($\"value\", \"\\\\t\").getItem(36))\n.withColumn(\"Actor1Geo_CountryCode\", split($\"value\", \"\\\\t\").getItem(37))\n.withColumn(\"Actor1Geo_ADM1Code\", split($\"value\", \"\\\\t\").getItem(38))\n.withColumn(\"Actor1Geo_ADM2Code\", split($\"value\", \"\\\\t\").getItem(39))\n.withColumn(\"Actor1Geo_Lat\", split($\"value\", \"\\\\t\").getItem(40))\n.withColumn(\"Actor1Geo_Long\", split($\"value\", \"\\\\t\").getItem(41))\n.withColumn(\"Actor1Geo_FeatureID\", split($\"value\", \"\\\\t\").getItem(42))\n.withColumn(\"Actor2Geo_Type\", split($\"value\", \"\\\\t\").getItem(43))\n.withColumn(\"Actor2Geo_FullName\", split($\"value\", \"\\\\t\").getItem(44))\n.withColumn(\"Actor2Geo_CountryCode\", split($\"value\", \"\\\\t\").getItem(45))\n.withColumn(\"Actor2Geo_ADM1Code\", split($\"value\", \"\\\\t\").getItem(46))\n.withColumn(\"Actor2Geo_ADM2Code\", split($\"value\", \"\\\\t\").getItem(47))\n.withColumn(\"Actor2Geo_Lat\", split($\"value\", \"\\\\t\").getItem(48))\n.withColumn(\"Actor2Geo_Long\", split($\"value\", \"\\\\t\").getItem(49))\n.withColumn(\"Actor2Geo_FeatureID\", split($\"value\", \"\\\\t\").getItem(50))\n.withColumn(\"ActionGeo_Type\", split($\"value\", \"\\\\t\").getItem(51))\n.withColumn(\"ActionGeo_FullName\", split($\"value\", \"\\\\t\").getItem(52))\n.withColumn(\"ActionGeo_CountryCode\", split($\"value\", \"\\\\t\").getItem(53))\n.withColumn(\"ActionGeo_ADM1Code\", split($\"value\", \"\\\\t\").getItem(54))\n.withColumn(\"ActionGeo_ADM2Code\", split($\"value\", \"\\\\t\").getItem(55))\n.withColumn(\"ActionGeo_Lat\", split($\"value\", \"\\\\t\").getItem(56))\n.withColumn(\"ActionGeo_Long\", split($\"value\", \"\\\\t\").getItem(57))\n.withColumn(\"ActionGeo_FeatureID\", split($\"value\", \"\\\\t\").getItem(58))\n.withColumn(\"DATEADDED\", split($\"value\", \"\\\\t\").getItem(59))\n.withColumn(\"SOURCEURL\", split($\"value\", \"\\\\t\").getItem(60))\n.drop(\"value\")\n\n// MENTIONS\nval dfMentionsRenamed: DataFrame = textRDDMentions.toDF.withColumn(\"GLOBALEVENTID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"GLOBALEVENTID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"EventTimeDate\", split($\"value\", \"\\\\t\").getItem(1))\n.withColumn(\"MentionTimeDate\", split($\"value\", \"\\\\t\").getItem(2))\n.withColumn(\"MentionType\", split($\"value\", \"\\\\t\").getItem(3))\n.withColumn(\"MentionSourceName\", split($\"value\", \"\\\\t\").getItem(4))\n.withColumn(\"MentionIdentifier\", split($\"value\", \"\\\\t\").getItem(5))\n.withColumn(\"SentenceID\", split($\"value\", \"\\\\t\").getItem(6))\n.withColumn(\"Actor1CharOffset\", split($\"value\", \"\\\\t\").getItem(7))\n.withColumn(\"Actor2CharOffset\", split($\"value\", \"\\\\t\").getItem(8))\n.withColumn(\"ActionCharOffset\", split($\"value\", \"\\\\t\").getItem(9))\n.withColumn(\"InRawText\", split($\"value\", \"\\\\t\").getItem(10))\n.withColumn(\"Confidence\", split($\"value\", \"\\\\t\").getItem(11))\n.withColumn(\"MentionDocLen\", split($\"value\", \"\\\\t\").getItem(12))\n.withColumn(\"MentionDocTone\", split($\"value\", \"\\\\t\").getItem(13))\n.withColumn(\"MentionDocTranslationInfo\", split($\"value\", \"\\\\t\").getItem(14))\n.withColumn(\"Extras\", split($\"value\", \"\\\\t\").getItem(15))\n.drop(\"value\")\n\n// RELATION GRAPH\nval dfRelationsRenamed: DataFrame = textRDDRelations.toDF.withColumn(\"GLOBALEVENTID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"GKGRECORDID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"DATE\", split($\"value\", \"\\\\t\").getItem(1))\n.withColumn(\"SourceCollectionIdentifier\", split($\"value\", \"\\\\t\").getItem(2))\n.withColumn(\"SourceCommonName\", split($\"value\", \"\\\\t\").getItem(3))\n.withColumn(\"DocumentIdentifier\", split($\"value\", \"\\\\t\").getItem(4))\n.withColumn(\"Counts\", split($\"value\", \"\\\\t\").getItem(5))\n.withColumn(\"V2Counts\", split($\"value\", \"\\\\t\").getItem(6))\n.withColumn(\"Themes\", split($\"value\", \"\\\\t\").getItem(7))\n.withColumn(\"V2Themes\", split($\"value\", \"\\\\t\").getItem(8))\n.withColumn(\"Locations\", split($\"value\", \"\\\\t\").getItem(9))\n.withColumn(\"V2Locations\", split($\"value\", \"\\\\t\").getItem(10))\n.withColumn(\"Persons\", split($\"value\", \"\\\\t\").getItem(11))\n.withColumn(\"V2Persons\", split($\"value\", \"\\\\t\").getItem(12))\n.withColumn(\"Organizations\", split($\"value\", \"\\\\t\").getItem(13))\n.withColumn(\"V2Organizations\", split($\"value\", \"\\\\t\").getItem(14))\n.withColumn(\"V2Tone\", split($\"value\", \"\\\\t\").getItem(15))\n.withColumn(\"Dates\", split($\"value\", \"\\\\t\").getItem(16))\n.withColumn(\"GCAM\", split($\"value\", \"\\\\t\").getItem(17))\n.withColumn(\"SharingImage\", split($\"value\", \"\\\\t\").getItem(18))\n.withColumn(\"RelatedImages\", split($\"value\", \"\\\\t\").getItem(19))\n.withColumn(\"SocialImageEmbeds\", split($\"value\", \"\\\\t\").getItem(20))\n.withColumn(\"SocialVideoEmbeds\", split($\"value\", \"\\\\t\").getItem(21))\n.withColumn(\"Quotations\", split($\"value\", \"\\\\t\").getItem(22))\n.withColumn(\"AllNames\", split($\"value\", \"\\\\t\").getItem(23))\n.withColumn(\"Amounts\", split($\"value\", \"\\\\t\").getItem(24))\n.withColumn(\"TranslationInfo\", split($\"value\", \"\\\\t\").getItem(25))\n.withColumn(\"Extras\", split($\"value\", \"\\\\t\").getItem(26))\n.drop(\"value\")","user":"anonymous","dateUpdated":"2020-01-20T16:24:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.sql.{DataFrame, SparkSession}\nimport org.apache.spark.input.PortableDataStream\nimport org.apache.spark.sql.functions._\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\nimport com.datastax.spark.connector.cql.CassandraConnector\nimport org.apache.spark.sql.cassandra._\nimport org.apache.spark.rdd.RDD\nimport spark.implicits._\nAWS_ID: String = ASIATATIKUDEPGIKRX7U\nAWS_KEY: String = eFcCfe102hBpKuqNYu+ftfXBKw3CRDc778XUfQKS\nAWS_TOKEN: String = FwoGZXIvYXdzEHEaDCvYeYPJmwLsNeE6GyLMAVMNSbiFqj4XVtMlP8ZJgy3bEJLwwtp5e1HN4VefHrVBaltIMp8mr0LaQC5N4AVEFl+X3do1EI/fYWpSZOCGjvzgCsi9QX0uwf/E3eA6Tqd3w+tZGyKSa1Lx3wvFjWiWwZeNJvREUn+r3xamVTozpvIfym83Wd39JxBsMHHrEhOVM9+kPu474Ctb6DmUWcWknyrC..."}]},"apps":[],"jobName":"paragraph_1579506869475_310222018","id":"20200120-075429_773920994","dateCreated":"2020-01-20T07:54:29+0000","dateStarted":"2020-01-20T16:24:49+0000","dateFinished":"2020-01-20T16:24:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2606"},{"text":"val dfEventsForJoin = dfEventsRenamed.select(\"GLOBALEVENTID\",\"DAY\",\"Actor1CountryCode\")\nval dfMentionsForJoin = dfMentionsRenamed.select(\"GLOBALEVENTID\",\"MentionDocTranslationInfo\")","user":"anonymous","dateUpdated":"2020-01-20T16:24:59+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dfEventsForJoin: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, DAY: string ... 1 more field]\ndfMentionsForJoin: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, MentionDocTranslationInfo: string]\n"}]},"apps":[],"jobName":"paragraph_1579511814826_-1409508171","id":"20200120-091654_2139418060","dateCreated":"2020-01-20T09:16:54+0000","dateStarted":"2020-01-20T16:24:59+0000","dateFinished":"2020-01-20T16:25:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2607"},{"text":"val dfJoin = dfEventsForJoin.join(dfMentionsForJoin, Seq(\"GLOBALEVENTID\"))","user":"anonymous","dateUpdated":"2020-01-20T16:25:03+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dfJoin: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, DAY: string ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579510547919_-361376700","id":"20200120-085547_1870761692","dateCreated":"2020-01-20T08:55:47+0000","dateStarted":"2020-01-20T16:25:03+0000","dateFinished":"2020-01-20T16:25:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2608"},{"text":"val dfGroup = dfJoin\n.groupBy(\"DAY\", \"Actor1CountryCode\", \"MentionDocTranslationInfo\")\n.agg(count(\"GLOBALEVENTID\").alias(\"count_events\"))\n.withColumnRenamed(\"DAY\",\"date\")\n.withColumnRenamed(\"Actor1CountryCode\", \"country\")\n.withColumnRenamed(\"MentionDocTranslationInfo\", \"language_0\")","user":"anonymous","dateUpdated":"2020-01-20T16:25:05+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dfGroup: org.apache.spark.sql.DataFrame = [date: string, country: string ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579510678300_-993491973","id":"20200120-085758_443214465","dateCreated":"2020-01-20T08:57:58+0000","dateStarted":"2020-01-20T16:25:05+0000","dateFinished":"2020-01-20T16:25:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2609"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579534400778_-543448223","id":"20200120-153320_1477346658","dateCreated":"2020-01-20T15:33:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3707","text":"def preprocessLanguages(s: String): String = {\n    if(s == \"\") {\n        \"eng\"\n    } else {\n        s.split(\";\")(0).split(\":\")(1)\n    }\n}\n\nval preprocessLanguagesUDF = udf(preprocessLanguages _)","dateUpdated":"2020-01-20T16:25:08+0000","dateFinished":"2020-01-20T16:25:08+0000","dateStarted":"2020-01-20T16:25:08+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"preprocessLanguages: (s: String)String\npreprocessLanguagesUDF: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579534111368_837916235","id":"20200120-152831_854135524","dateCreated":"2020-01-20T15:28:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3611","text":"val dfLanguagePreproc = dfGroup.withColumn(\"language\", preprocessLanguagesUDF($\"language_0\")).drop(\"language_0\")","dateUpdated":"2020-01-20T16:25:11+0000","dateFinished":"2020-01-20T16:25:12+0000","dateStarted":"2020-01-20T16:25:11+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dfLanguagePreproc: org.apache.spark.sql.DataFrame = [date: string, country: string ... 2 more fields]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579536133141_-540362856","id":"20200120-160213_2094187620","dateCreated":"2020-01-20T16:02:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4754","text":"val reorderedColumnNames = Array(\"date\",\"country\",\"language\",\"count_events\")\nval dfReordered = dfLanguagePreproc.select(reorderedColumnNames.head, reorderedColumnNames.tail: _*)","dateUpdated":"2020-01-20T16:25:14+0000","dateFinished":"2020-01-20T16:25:14+0000","dateStarted":"2020-01-20T16:25:14+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"reorderedColumnNames: Array[String] = Array(date, country, language, count_events)\ndfReordered: org.apache.spark.sql.DataFrame = [date: string, country: string ... 2 more fields]\n"}]}},{"text":"CassandraConnector(sc.getConf).withSessionDo { session =>\n      session.execute(\n        \"\"\"\n           CREATE KEYSPACE IF NOT EXISTS gdelt\n           WITH REPLICATION =\n           {'class': 'SimpleStrategy', 'replication_factor': 2 };\n        \"\"\")\n        session.execute(\n        \"\"\"\n           CREATE TABLE IF NOT EXISTS gdelt.query1 (\n              date text,\n              country text,\n              language text,\n              count_events int,\n              PRIMARY KEY (date, country, language)\n            );\n        \"\"\"\n      )\n}","user":"anonymous","dateUpdated":"2020-01-20T16:27:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res30: com.datastax.driver.core.ResultSet = ResultSet[ exhausted: true, Columns[]]\n"}]},"apps":[],"jobName":"paragraph_1579508257434_1060692042","id":"20200120-081737_507399515","dateCreated":"2020-01-20T08:17:37+0000","dateStarted":"2020-01-20T16:27:23+0000","dateFinished":"2020-01-20T16:27:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2611"},{"text":"dfReordered.write\n      .cassandraFormat(\"query1\", \"gdelt\")\n      .save()","user":"anonymous","dateUpdated":"2020-01-20T16:27:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.SparkException: Job 54 cancelled part of cancelled job group zeppelin-anonymous-2EZGWZQMZ-20200120-080331_1066883387\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1976)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:946)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:946)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:946)\n  at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:946)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2231)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n  at com.datastax.spark.connector.RDDFunctions.saveToCassandra(RDDFunctions.scala:36)\n  at org.apache.spark.sql.cassandra.CassandraSourceRelation.insert(CassandraSourceRelation.scala:76)\n  at org.apache.spark.sql.cassandra.DefaultSource.createRelation(DefaultSource.scala:90)\n  at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:156)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n  ... 65 elided\n"}]},"apps":[],"jobName":"paragraph_1579507411406_-569947233","id":"20200120-080331_1066883387","dateCreated":"2020-01-20T08:03:31+0000","dateStarted":"2020-01-20T16:27:27+0000","dateFinished":"2020-01-20T16:33:17+0000","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:2612"},{"text":"val query1 = spark.read\n      .cassandraFormat(\"query1\", \"gdelt\")\n      .load()","user":"anonymous","dateUpdated":"2020-01-20T16:14:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"query1: org.apache.spark.sql.DataFrame = [date: string, country: string ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579511187009_642804988","id":"20200120-090627_1619175767","dateCreated":"2020-01-20T09:06:27+0000","dateStarted":"2020-01-20T16:14:42+0000","dateFinished":"2020-01-20T16:14:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2613"}],"name":"cassandraQuery1","id":"2EZGWZQMZ","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}